---
title: "Bayesian-networks"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Collaborators : Andrej Betik(456604), Petr Klanica(469223), Marcel Kubík(433719)

```{r include=FALSE}
# Packages installation
install_pckgs_if_not_installed <- function(pkg){
    new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
    if (length(new.pkg)) 
        install.packages(new.pkg, dependencies = TRUE)
    sapply(pkg, require, character.only = TRUE)
}
pckgs <- c("ggplot2", "gridExtra", "mice", "caret", "arm", "ROSE", "forcats", "AnDE")
suppressWarnings(install_pckgs_if_not_installed(pckgs))
```

## 1. Introduction

1. Dataset : German Credit Data, Learning Algorithm : Bayesian Generalized Linear Model (Andrej Betik)
2. Dataset: Ramen Reviews, Learning Algorithm: Averaged One Dependency Estimator (Petr Klanica)
3. Dataset: Student Performance (Marcel Kubík)

## 2. Exploratory Analysis

### 1. German Credit Data

This dataset contains data about people attempting to take a credit by the bank. Each person represents a Good Risk or Bad Risk for bank.

Good Risk:
An assumption that customer who takes a credit will be able to pay invoices. The bank tends to give a credit to this customer

Bad Risk:
A loan that is unlikely to be repaid because of bad credit history, insufficient income, or some other reason.

The original dataset contains 1000 entries with 20 categorial/symbolic attributes prepared by Prof. Hofmann. The original dataset can be found at https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29

Hoverever the original dataset is kind of messy so I got simplified and well documented version from kaggle site https://www.kaggle.com/uciml/german-credit

#### The selected atributes are:
1. Age (numeric)
2. Sex (text: male, female)
3. Job (numeric: 0 - unskilled and non-resident, 1 - unskilled and resident, 2 - skilled, 3 - highly skilled)
4. Housing (text: own, rent, or free)
5. Saving accounts (text - little, moderate, quite rich, rich)
6. Checking account (numeric, in DM - Deutsch Mark)
7. Credit amount (numeric, in DM)
8. Duration (numeric, in month)
9. Purpose (text: car, furniture/equipment, radio/TV, domestic appliances, repairs, education, business, vacation/others)
10. Risk(Target value- Goor or Bad Risk)

First look at the data

```{r}
#loading the dataset
german_credit_data <- read.csv("data/german_credit_data.csv")
# deleting the index column, the author was using that to uniquely identify every row
german_credit_data = german_credit_data[,-1]
# showing all the attributes and values it can take
str(german_credit_data)
```

Proportion of Good / Bad risk

```{r}
barplot(c(table(german_credit_data$Risk)), col = c("red", "blue"))
```

Attribute Distributions
```{r}
par(mfrow=c(3,2))
hist(german_credit_data$Age, xlab = "Age", main = "Age Distribution")
hist(german_credit_data$Job, xlab = "Job  (0-non-resident,1-resident,2-skilled,3-highly skilled)", main = "Job Distribution")
hist(german_credit_data$Credit.amount, xlab = "Credit Amount", main = "Credit Amount Distribution")
hist(german_credit_data$Duration, xlab = "Duration", main = "Duration Distribution")
hist(as.numeric(german_credit_data$Housing), xlab = "Housing  (1-free, 2-own, 3-rent)", main = "Housing Distribution")
barplot(c(table(german_credit_data$Sex)))

```


Inspection of interesting data features
```{r}
# People at very young age seem to have worse credit worthiness
p1 <- ggplot(german_credit_data, aes(x=Age, color=Risk)) + geom_density()
# The shorter the credit loan duration, the better the chance of getting loan"
p2 <- ggplot(german_credit_data, aes(x=Duration, color=Risk)) + geom_density()
# A trend of "Higher credit amount, better credit worthiness"
p3 <- ggplot(german_credit_data, aes(x=Credit.amount, color=Risk)) + geom_density()
grid.arrange(p1, p2, p3)
```

Inspection of NA values
```{r}
number_of_na_values <- sum(is.na(german_credit_data))
number_of_not_na_values <- sum(!is.na(german_credit_data))
# Proportion of number of NA values and number of normal(not NA values) out of all values
barplot(c(number_of_na_values, number_of_not_na_values), names.arg = c("NA", "Not NA"))
```

Na values occur only in attributes Savings Account and Checking account
```{r}
sum(is.na(german_credit_data))
sum(is.na(german_credit_data$Saving.accounts)) + sum(is.na(german_credit_data$Checking.account))

```
### 2. Ramen Reviews
This dataset contains over 2000 reviews for different instant ramen soups. The goal I set was to try and estimate review score based on the other features. However this dataset is very dirty and very basic so it will require some cleaning and feature extraction to be more useable. Let's take a look at the data.
```{r}
ramen_reviews <- read.csv("data/ramen-ratings.csv")
summary(ramen_reviews)
```
As we can see, there are few useless columns like review number or Top Ten rating. There are also a few other noteworthy columns:

1. Brand: We can see that there are a few brands that have significant representation, but there are many others that have just a few soups in the list. This brings us to a question wether to remove this column entirely or not. I belive that even though we will probably only preserve a few of the brands and cluster most of the remaining ones into an "other" category, the brand can still tell us a lot about the quality of the soup and because Bayesian models tend to handle noise pretty well, I have decided to keep the column in the dataset.

2. Country: Situation here is similar to Brand column and for the same reason this column will be kept but most countries will be clumped together into "other".

  3. Variety: This is the most important column in this dataset. As you can see, almost every soup has an unique name here, most of which include at least a hint as to what is inside the soup. Therefore we will extract additional features from this column such as type of food  used for broth, type of noodles or wether the soup is spicy or not. We will create a one-hot encoding of all these new features (see data preprocessing chapter for further details). Additionally, we will then delete soups that we weren't able to extract any features from, those will mostly be soups that rely only on their brand/product name and not on description of the contents. (later we will see that this way we will only lose about 350 soups)

```{r}
ramen_reviews <- read.csv("data/ramen-ratings.csv")
summary(ramen_reviews$Stars)
```
If we take a closer look at Stars column, we find out that in addition to having 3 NA values ("Unrated" in this case), we also find out that despite the rating being in stars, there are a lot of fractions which will require us to group some of the ratings together. Additionally we can see that the ratings are heavily skewed towards 3 and 4 which we will have to keep in mind when grouping ratings together.

### 3. Student Performance

This dataset targets relationships of demographic, social and school related features with student's school grades. Data have been collected from two Portuguese schools. From two subjects, math has been chosen for the classification. The dataset, originally, contains each student's final grade, which will be divided into two intervals of passing and not passing students. According to Portuguese grading system, a student passes (the grade meets requirements fot the student to pass the year), if the final grade is above or equal 10.  
The dataset reference is located at https://archive.ics.uci.edu/ml/datasets/Student+Performance  

Due to higher total count of features, selected features are:  
1. reason - reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other')  
2. studytime - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)  
3. failures - number of past class failures (numeric: n if 1<=n<3, else 4)  
4. paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)  
5. higher - wants to take higher education (binary: yes or no)  
6. romantic - with a romantic relationship (binary: yes or no)  
7. famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)  
8. freetime - free time after school (numeric: from 1 - very low to 5 - very high)  
9. goout - going out with friends (numeric: from 1 - very low to 5 - very high)  
10. absences - number of school absences (numeric: from 0 to 93)  
11. Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)  
  
The class feature "passed" has been created by determining, from final grade (feature "G3"), whether the student passed or not.  

## 3. Preprocessing
### 1. German Credit Data
Since this dataset contains a lot of NA values, lets get rid of it with function mice
```{r}
# Number of NA values
sum(is.na(german_credit_data))
# First 5 NA values
head(german_credit_data[, c(5,6)])
german_credit_data <- complete(mice(german_credit_data))
sum(is.na(german_credit_data))
head(german_credit_data[, c(5,6)])
```

Apparantly this dataset is unballanced(has unequal number of instances for different classes)

```{r}
table(german_credit_data$Risk)
```

Using function ovun.sample to ballance the data
It creates possibly balanced samples by combination of random over-sampling minority examples and under-sampling
majority examples.
Over/Under sampling whole dataset would create copies of the same point.
It may end up in both the training and test sets. This allows the classifier to cheat.
Firstly I will divide the dataset to train/test and over/under sample just the train one.
```{r}
set.seed(123)
indicies <- createDataPartition(german_credit_data$Risk, p = 0.6, list=FALSE)
german_credit_train <- german_credit_data[indicies, ]
german_credit_test <- german_credit_data[-indicies, ]
train_balanced_german_data <- ovun.sample(Risk ~., data=german_credit_train)$data
table(train_balanced_german_data$Risk)
```

Test data are still unbalanced but not really much to do with it.
```{r}
table(german_credit_test$Risk)
```

### 2. Ramen Reviews
First of all we remove rows with missing rating and rows where Style column contains invalid, missing or very rare values. Since there are very few of them we can afford to just remove them.
```{r}
ramen_reviews <- read.csv("data/ramen-ratings.csv")

#remove unrated entries
ramen_reviews <- ramen_reviews[ramen_reviews$Stars != "Unrated", ]

#remove entries with invalid or infrequent Style
ramen_reviews$Style <- fct_lump(ramen_reviews$Style, n=4)
ramen_reviews <- ramen_reviews[ramen_reviews$Style != "Other" ,]
```

Now we extract features from text description ("Variety" column)
```{r}
#extracting features from "Variety"
ramen_reviews$Beef <- grepl("(\\b|\\w)(beef|bo|gomtang|gomguk)(\\b|\\w)", ramen_reviews$Variety, ignore.case=TRUE, perl=TRUE)
ramen_reviews$Pork <- grepl("(\\b|\\w)(pork|tonkotsu|myeon|myun)(\\b|\\w)", ramen_reviews$Variety, ignore.case=TRUE, perl=TRUE)
ramen_reviews$Chicken <- grepl("(\\b|\\w)(Bird|ga|chicken|duck|kung|gung|laksa|chikin)(\\b|\\w)", ramen_reviews$Variety, ignore.case=TRUE, perl=TRUE)
ramen_reviews$Vegetable <- grepl("(\\b|\\w)(Vegetable|mushroom|vegetarian|tomato|onion|veggie|shroom|radish)(\\b|\\w)", ramen_reviews$Variety, ignore.case=TRUE, perl=TRUE)
ramen_reviews$Miso <- grepl("(\\b|\\w)(miso)(\\b|\\w)", ramen_reviews$Variety, ignore.case=TRUE, perl=TRUE)
ramen_reviews$WheatNoodles <- grepl("(\\b|\\w)(udon|wheat|oat|udoin|tempura|soba|u-dong)(\\b|\\w)", ramen_reviews$Variety, ignore.case=TRUE, perl=TRUE)
ramen_reviews$Spicy <- grepl("(\\b|\\w)(hot|kimchi|spicy|pepper|yung|yum|masala|laksa|chili|chilli|curry|spice)(\\b|\\w)", ramen_reviews$Variety, ignore.case=TRUE, perl=TRUE)
ramen_reviews$Seafood <- grepl("(\\b|\\w)(sea|food|crab|cua|fish|tom|seafood|oyster|shrimp|scallop|mentaiko|myeongnan|myeong|pollack|pollock|clam|prawn)(\\b|\\w)", ramen_reviews$Variety, ignore.case=TRUE, perl=TRUE)
ramen_reviews$Sesame <- grepl("(\\b|\\w)(sesame)(\\b|\\w)", ramen_reviews$Variety, ignore.case=TRUE, perl=TRUE)
ramen_reviews$RiceNoodles <- grepl("(\\b|\\w)(Rice|pad)(\\b|\\w)", ramen_reviews$Variety, ignore.case=TRUE, perl=TRUE)
ramen_reviews$Soy <- grepl("(\\b|\\w)(soy|shio|shoyu)(\\b|\\w)", ramen_reviews$Variety, ignore.case=TRUE, perl=TRUE)
ramen_reviews$StirFried <- grepl("(\\b|\\w)(stir|fried|stirfried|goreng|pad)(\\b|\\w)", ramen_reviews$Variety, ignore.case=TRUE, perl=TRUE)
ramen_reviews$Creamy <- grepl("(\\b|\\w)(creamy|cream)(\\b|\\w)", ramen_reviews$Variety, ignore.case=TRUE, perl=TRUE)
ramen_reviews$Oriental <- grepl("(\\b|\\w)(oriental)(\\b|\\w)", ramen_reviews$Variety, ignore.case=TRUE, perl=TRUE)

#remove all ramen that we weren't able to extract any features from
ramen_reviews <- ramen_reviews[rowSums(sapply(ramen_reviews[,c(8:21)], identity))!=0,]
```

Finally we clean up Star rating and transform numerical score into four categories. Then we clump infrequent values in Country and Brand to "Other". Lastly we remove obsoleted columns and drop unused levels from factors.
```{R}
#clumping infrequent countries of origin and brands together
ramen_reviews$Country <- fct_lump(ramen_reviews$Country, prop=0.02)
ramen_reviews$Brand <- fct_lump(ramen_reviews$Brand, prop=0.02)

#clean up factors by dropping unused levels
ramen_reviews <- droplevels(ramen_reviews)

#group stars into four categories
rrf <- factor(c("bad", "average", "good", "great"))
rr4 <- (subset(ramen_reviews, grepl("^(5|4.5|4.7)", Stars, ignore.case=TRUE, perl=TRUE)))
rr4$Rating <- rrf[4]
rr3 <- (subset(ramen_reviews, grepl("^(4$|4.0|4.1|4.2|4.3)", Stars, ignore.case=TRUE, perl=TRUE)))
rr3$Rating <- rrf[3]
rr2 <- (subset(ramen_reviews, grepl("^(3.5|3.6|3.7|3.8)", Stars, ignore.case=TRUE, perl=TRUE)))
rr2$Rating <- rrf[2]
rr1 <- (subset(ramen_reviews, grepl("^(0|1|2|3$|3.0|3.1|3.2|3.3|3.4)", Stars, ignore.case=TRUE, perl=TRUE)))
rr1$Rating <- rrf[1]
ramen_reviews <- rbind(rr3, rr4, rr2, rr1)

#removing useless or obsoleted columns
ramen_reviews <- subset(ramen_reviews, select = -c(Variety, Stars, Top.Ten, Review..))
```

### 3. Student Performance

```{r}
student_performance = read.csv2("data/student-mat.csv")

# grade categorization
student_performance$passed = cut(student_performance$G3, labels = c("N", "P"), breaks = seq(0, 20, by = 10), right = FALSE)

# omitting NAs and selecting desired columns
student_performance = na.omit(student_performance)[, c("reason", "studytime", "failures", "paid", "higher", "romantic", "famrel", "freetime", "goout", "absences", "Dalc", "passed")]

# translating some feature values from ints to more understandable form
student_performance$studytime[student_performance$studytime == "1"] = "less_than_2_hours"
student_performance$studytime[student_performance$studytime == "2"] = "2_to_5_hours"
student_performance$studytime[student_performance$studytime == "3"] = "5_to_10_hours"
student_performance$studytime[student_performance$studytime == "4"] = "more_than_10_hours"

# omitting unused feature values (e.g. failures: "4")
student_performance = droplevels(student_performance)
```

## 4. Learning Algorithms
### 1. Bayesian Generalized Linear Model
The  generalized linear model (GLM) is a flexible generalization of ordinary linear regression that allows for response variables that have error distribution models other than a normal distribution. The GLM generalizes linear regression by allowing the linear model to be related to the response variable via a link function and by allowing the magnitude of the variance of each measurement to be a function of its predicted value.

The GLM consists of three elements:

1. An exponential family of probability distributions.
2. A linear predictor η = Xβ .
3. A link function g such that E(Y|X) = μ = g−1(η).

### 2. Bayesian Averaged One Dependency Estimator (AODE)
AODE works similarly to naive Bayes however it avoids assuming feature independence. For dataset with n features AODE creates n models where each model assumes that i-th feature is dependent on all other features while all other features are independent of each other. Thus it can model up to quadratic dependencies accurately. Result returned by AODE is a simple average of all n models.

## 5. Evaluation
### 1. Bayesian Generalized Linear Model

I'v made a function that performs the training process multiple times so the random paritioning doesn't effect the process.

iterations - number of iterations, splitPercantage - the train/test partition ratio

```{r}
set.seed(123)
germanEvaluation <- function(iterations, splitPercentage ) {
  accuracies <- numeric(iterations)
  for (i in 1:iterations) {
    # I have created the partition train/test before in the preprocess section but it was just for explain purposes.
    # Now its partitioned again in every iteration in cycle.
    # The same holds for balancing the data.
    indicies <- createDataPartition(german_credit_data$Risk, p = splitPercentage, list=FALSE)
    german_credit_train <- german_credit_data[indicies, ]
    german_credit_test <- german_credit_data[-indicies, ]
    train_balanced_german_data <- ovun.sample(Risk ~., data=german_credit_train)$data
  
    bayesglm_german_credit_model <- train(Risk ~., data=train_balanced_german_data, method="bayesglm",
                                          trControl = trainControl(method = "cv", number=3))
    
    bayesglm_german_credit_prediction <- predict(bayesglm_german_credit_model, german_credit_test)
    conf <- suppressWarnings(confusionMatrix(bayesglm_german_credit_prediction, german_credit_test$Risk))
    accuracies[i] <- conf$overall['Accuracy']
    cat("-", sep="") # just to see the progress of training
  }
  cat("\n")
  cat("Best accuracy for split ratio" , splitPercentage, " : ", max(accuracies))
  accuracies
}
eval1 <- germanEvaluation(30, 0.7)
eval2 <- germanEvaluation(30, 0.95)
```

```{r}
boxplot(eval1, eval2)
```

### 2. AODE
#### 1. German Credit Data

```{r}
set.seed(123)
aode_german_evaluation <- function(iterations, splitPercentage ) {
  accuracies <- numeric(iterations)
  for (i in 1:iterations) {
    indicies <- createDataPartition(german_credit_data$Risk, p = splitPercentage, list=FALSE)
    german_credit_train <- german_credit_data[indicies, ]
    german_credit_test <- german_credit_data[-indicies, ]
  
    aode_german_credit_model <- aode(german_credit_train)
    
    aode_german_credit_prediction <- predict(aode_german_credit_model, german_credit_test)
    conf <- table(aode_german_credit_prediction, german_credit_test$Risk)
    accuracies[i] <- ((conf[1,1] + conf[2,2])/length(aode_german_credit_prediction))
    cat("-", sep="") # just to see the progress of training
  }
  cat("\n")
  cat("Best accuracy for split ratio" , splitPercentage, " : ", max(accuracies))
  accuracies
}
aode_ger_eval1 <- aode_german_evaluation(30, 0.7)
aode_ger_eval2 <- aode_german_evaluation(30, 0.95)
boxplot(aode_ger_eval1, aode_ger_eval2)
```
#### 2. Ramen Reviews

Since the classes of Rating can be considered ordered, it would be best to use evaluation methods usually used for regression. In this case we will use analogy of MSE (assuming all classes are 1 unit away from their neighbours)
```{r aode_ramen}
#table = confusion matrix, n = number of instances of test data
ramen_squared_error <- function(table, n) {
  error <- 0
  for (i in 1:4) {
    for (j in 1:4) {
      #print(error)
      #print(table[i,j])
      error <- (error + (table[i,j] * abs(i - j))) 
    }
  }
  error <- error / n
  error
}

set.seed(123)
aode_ramen_evaluation <- function(iterations, splitPercentage ) {
  errors <- numeric(iterations)
  for (i in 1:iterations) {
    indicies <- createDataPartition(ramen_reviews$Rating, p = splitPercentage, list=FALSE)
    ramen_train <- ramen_reviews[indicies, ]
    ramen_test <- ramen_reviews[-indicies, ]
    #train_balanced_german_data <- ovun.sample(Risk ~., data=german_credit_train)$data
  
    aode_ramen_model <- aode(ramen_train)
    
    aode_ramen_prediction <- predict(aode_ramen_model, ramen_test)
    conf <- table(aode_ramen_prediction, ramen_test$Rating)
    errors[i] <- ramen_squared_error(conf, length(aode_ramen_prediction))
    cat("-", sep="") # just to see the progress of training
  }
  cat("\n")
  cat("Best error for split ratio" , splitPercentage, " : ", min(errors))
  errors
}
aode_ramen_eval1 <- aode_ramen_evaluation(15, 0.7)
aode_ramen_eval2 <- aode_ramen_evaluation(15, 0.95)
boxplot(aode_ramen_eval1, aode_ramen_eval2)

```

## 6. Conclusion
### 1. German Credit Data
Bayesian Generalized Linear Model results :
Within the scope 70%(train) 30%(test), best accuracy is around 0.7.
On 95%(train) 5% test, best accuracy is around 0.75.
The results are pretty poor. However the size of the dataset is not large and test set is really unbalanced(120/280 - bad/good). Therefore I think it gave us decent predictions.

## 7. References
https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29  
https://www.kaggle.com/uciml/german-credit  
https://en.wikipedia.org/wiki/Generalized_linear_model
